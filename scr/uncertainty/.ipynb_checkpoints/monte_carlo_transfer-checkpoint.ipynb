{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status code:\n",
    "# 0: Normal transfers\n",
    "# 1: Missed transfers\n",
    "# 2: Preemptive transfers\n",
    "# 3: missing_a\n",
    "# 4: missing_b\n",
    "# 5: missing_records\n",
    "# 6: Critical transfers\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "from pymongo import MongoClient\n",
    "from datetime import timedelta, date\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database setup\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db_GTFS = client.cota_gtfs\n",
    "db_realtime = client.cota_real_time\n",
    "db_history = client.cota_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1517430037, 1519664424, 1520018797, 1521822323, 1522874132, 1525099492, 1525359840, 1525656730, 1526493697, 1527866762, 1528821689, 1530197142, 1531503899, 1533141303, 1533824930, 1535862053]\n"
     ]
    }
   ],
   "source": [
    "# Find the timestamp of all GTFS static checkpoints\n",
    "db_time_stamps_set = set()\n",
    "db_time_stamps = []\n",
    "raw_stamps = db_GTFS.list_collection_names ()\n",
    "for each_raw in raw_stamps:\n",
    "    each_raw = int(each_raw.split(\"_\")[0])\n",
    "    db_time_stamps_set.add(each_raw)\n",
    "\n",
    "for each_raw in db_time_stamps_set:\n",
    "    db_time_stamps.append(each_raw)\n",
    "db_time_stamps.sort()\n",
    "print(db_time_stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the corresponding GTFS static timestamp of a certain date.\n",
    "def find_gtfs_time_stamp(today_date, single_date):\n",
    "    today_seconds = int(\n",
    "        (single_date - date(1970, 1, 1)).total_seconds()) + 18000\n",
    "    backup = db_time_stamps[0]\n",
    "    for each_time_stamp in db_time_stamps:\n",
    "        if each_time_stamp - today_seconds > 86400:# If the difference than a day, go forward.\n",
    "            return backup\n",
    "        backup = each_time_stamp\n",
    "    return db_time_stamps[len(db_time_stamps) - 1]# If not returned until the end, return the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertSeconds(BTimeString, single_date):\n",
    "    time = BTimeString.split(\":\")\n",
    "    hours = int(time[0])\n",
    "    minutes = int(time[1])\n",
    "    seconds = int(time[2])\n",
    "    return hours * 3600 + minutes * 60 + seconds + int((single_date - date(1970, 1, 1)).total_seconds()) + \\\n",
    "        18000  # +18000 is the time zone. Must consider light saving time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date): # Create a list of consequential dates\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def sortQuery(A): # A sort function\n",
    "    return A[\"seq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180201 1 48909\n"
     ]
    }
   ],
   "source": [
    "# date setup\n",
    "single_date = date(2018, 2, 1) # The date\n",
    "today_date = single_date.strftime(\"%Y%m%d\")  # date to YMD format\n",
    "that_time_stamp = find_gtfs_time_stamp(today_date, single_date) # Corresponding GTFS static timestamp\n",
    "today_weekday = single_date.weekday() # Weekday: to find service id. For service_id in COTA, Mon - Fri: 1, Sat: 2, Sun: 3.\n",
    "\n",
    "db_seq = db_GTFS[str(that_time_stamp) + \"_trip_seq\"]\n",
    "db_today_collection = db_history[today_date]\n",
    "if today_weekday < 5:\n",
    "    service_id = 1\n",
    "elif today_weekday == 5:\n",
    "    service_id = 2\n",
    "else:\n",
    "    service_id = 3\n",
    "\n",
    "db_dedicated_collection = client.cota_monte_carlo[today_date] # The monte-carloed transfer collection\n",
    "\n",
    "# The count of current dedicated collection\n",
    "count_ded_col = db_dedicated_collection.estimated_document_count()\n",
    "\n",
    "dedicated_route_id = 2 # The selected route id\n",
    "\n",
    "# data retrival\n",
    "# the scheduled transfers for today and designated route id: both directions (±) and both generating and receiving transfers （a_ro, generating transfer, and b_ro, receiving transfer）.\n",
    "db_validated_transfer = list(\n",
    "    db_today_collection.find({\"$or\":[{\"b_ro\":dedicated_route_id},{\"b_ro\":-dedicated_route_id},{\"a_ro\":dedicated_route_id},{\"a_ro\":-dedicated_route_id}]}))  # today's transfer\n",
    "\n",
    "\n",
    "db_realtime_collection = db_realtime[\"R\" + today_date]\n",
    "print(today_date, service_id, len(db_validated_transfer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2018-02-01 ]: Start.\n"
     ]
    }
   ],
   "source": [
    "Normal_count = 0\n",
    "Missed_count = 0\n",
    "None_count = 0\n",
    "Preemptive_count = 0\n",
    "Critical_count = 0\n",
    "Max_count = len(db_validated_transfer)\n",
    "print(\"[\", single_date, \"]: Start.\")\n",
    "\n",
    "records_collections = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-14-7f2c7d8981bb>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-14-7f2c7d8981bb>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    return False\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "for single_result in db_validated_transfer: # Emurate validated transfers.\n",
    "    a = time.time()\n",
    "\n",
    "    # If the status is normal/missed/preemptive, consider change it.\n",
    "    if single_result[\"status\"] < 3 or single_result[\"status\"] == 6:\n",
    "        single_result[\"nor_b_a_t\"] = single_result[\"b_a_t\"]\n",
    "        single_result[\"nor_b_a_seq\"] = single_result[\"b_a_seq\"]\n",
    "        single_result[\"nor_b_a_tr\"] = single_result[\"b_a_tr\"]\n",
    "\n",
    "        # reassess_flag to true, which means the revisit of transfers will change this specific transfer.\n",
    "        reassess_flag = True\n",
    "\n",
    "        flag = 0\n",
    "        # If the generating trip is the dedicated bus route.\n",
    "        if single_result[\"a_ro\"] == dedicated_route_id or single_result[\"a_ro\"] == -dedicated_route_id:\n",
    "            flag = \"a\"\n",
    "            # Revise a_real_time to a_time, which change the actual time to schedule time\n",
    "\n",
    "            single_result[\"a_r_t\"] = single_result[\"a_t\"]\n",
    "\n",
    "            false_trips_list = list(db_seq.find({\"service_id\": str(\n",
    "                service_id), \"stop_id\": single_result[\"b_st\"], \"route_id\": single_result[\"b_ro\"]}))  # Find all possible receiving bus according to the b_stop_id and b_route_id and service_id\n",
    "            # Sort the query results according to the seq. This is a full list of possible trips.\n",
    "            false_trips_list.sort(key=sortQuery)\n",
    "            b_a_tr = \"0\"  # b_alternative_trip_id\n",
    "            b_a_seq = \"\"  # b_alternative_seq_id = ATP's N\n",
    "            b_a_real_seq = 0\n",
    "            b_a_t = 9999999999  # b_alternative_time\n",
    "            # These three are the information of the actual receiving bus.\n",
    "\n",
    "            seq_query = list(db_seq.find({\"service_id\": str(\n",
    "                service_id), \"stop_id\": single_result[\"b_st\"], \"trip_id\": single_result[\"b_tr\"]}))  # To find the scheduled receiving bus's seq_id, query the b_trip_id in the trip_seq collection.\n",
    "            if seq_query == []:  # If there is no such a records, the scheduled receiving bus is not in the trip_seq, which is theoretical impossible.\n",
    "                b_a_t == -2\n",
    "\n",
    "            else:\n",
    "                # Select the first one in the seq_query (which can only have one.)\n",
    "                seq_query = seq_query[0]\n",
    "                # This is the seq_id of the scheduled receiving bus.\n",
    "                flag_sequence_id = seq_query[\"seq\"]\n",
    "\n",
    "                # For all the possible receiving buses, find the closest one as the actual receiving bus.\n",
    "                for each_trip in false_trips_list:\n",
    "                    i_trip_id = each_trip[\"trip_id\"]\n",
    "                    seq_id = each_trip[\"seq\"]\n",
    "                    # Find the b_alt_time for this trip_id and compare it to the b_alt_time (overall). Until we find the smallest one.\n",
    "                    # print(b_stop_id,str(i_trip_id))\n",
    "                    query_realtime = list(db_realtime_collection.find(\n",
    "                        {\"stop_id\": single_result[\"b_st\"], \"trip_id\": str(i_trip_id)}))  # Find each trip's real arrival time.\n",
    "                    if query_realtime == []:  # Cannot find the real time.\n",
    "                        # Which suggests that the bus is gone. We won't take care of it but to let it go till we find an existing bus.\n",
    "                        pass\n",
    "                        # This is tricky\n",
    "                    else:\n",
    "                        i_real_time = query_realtime[0][\"time\"]\n",
    "                        if b_a_t > i_real_time and i_real_time >= single_result[\"a_r_t\"] + single_result[\"w_t\"]:\n",
    "                            b_a_t = i_real_time\n",
    "\n",
    "                            # store the closest trip's seq_id.\n",
    "                            b_a_real_seq = seq_id\n",
    "                            b_a_seq = seq_id - flag_sequence_id\n",
    "                            b_a_tr = i_trip_id\n",
    "\n",
    "            # This means there's no alternative trip for this receiving trip. So you are doomed.\n",
    "            if b_a_t == 9999999999:\n",
    "                # print(single_result[\"b_st\"],single_result[\"b_tr\"])\n",
    "                b_a_t = -1  # there's no an alternative trip.\n",
    "                b_a_seq = None\n",
    "                b_a_tr = \"-1\"\n",
    "            # Become a missing record, which is pretty weird.\n",
    "            if b_a_t == -2:\n",
    "                b_a_seq = \"Missed\"\n",
    "                b_a_tr = \"-2\"\n",
    "\n",
    "            #print(single_result[\"b_st\"], single_result[\"a_ro\"], \"=>\", single_result[\"b_ro\"], \"|| \", single_result[\"a_r_t\"]-,  b_a_t,\n",
    "            #      \"ded: \", b_a_real_seq, \"schedule: \", flag_sequence_id, \"nor: \", single_result[\"nor_b_a_seq\"]+flag_sequence_id)\n",
    "\n",
    "        # If the receiving trip is the dedicated bus route.\n",
    "        elif single_result[\"b_ro\"] == dedicated_route_id or single_result[\"b_ro\"] == -dedicated_route_id:\n",
    "            # Which means we need to query from the GTFS static data.\n",
    "            flag = \"b\"\n",
    "            real_b_seq = list(db_seq.find({\"service_id\": str(service_id), \"stop_id\": single_result[\"b_st\"], \"route_id\": single_result[\"b_ro\"], \"time\": {\n",
    "                              \"$gte\": single_result[\"a_r_t\"] + single_result[\"w_t\"] - 18000 - int((single_date - date(1970, 1, 1)).total_seconds())}}).sort([(\"seq\", 1)]))\n",
    "            if real_b_seq==[]: # There is no possible \n",
    "                print(\"???\")\n",
    "            else:\n",
    "                real_b_seq=real_b_seq[0]\n",
    "                # print(real_b_seq)\n",
    "                b_a_t_real = real_b_seq[\"time\"] + \\\n",
    "                    int((single_date - date(1970, 1, 1)).total_seconds()) + 18000\n",
    "                b_a_seq_real = real_b_seq[\"seq\"]\n",
    "                b_a_tr_real = real_b_seq[\"trip_id\"]\n",
    "\n",
    "                schedule_b_seq = list(db_seq.find({\"service_id\": str(\n",
    "                    service_id), \"stop_id\": single_result[\"b_st\"], \"trip_id\": single_result[\"b_tr\"]}))[0]\n",
    "\n",
    "                b_a_seq_schedule = schedule_b_seq[\"seq\"]\n",
    "\n",
    "                b_a_t = b_a_t_real\n",
    "                b_a_seq = b_a_seq_real - b_a_seq_schedule\n",
    "                b_a_tr = b_a_tr_real\n",
    "\n",
    "        # If not assessed, then reassess_flag is False.\n",
    "        else:\n",
    "            reassess_flag = False\n",
    "\n",
    "        if reassess_flag == True:\n",
    "            single_result[\"b_a_t\"] = b_a_t\n",
    "            single_result[\"b_a_seq\"] = b_a_seq\n",
    "            single_result[\"b_a_tr\"] = b_a_tr\n",
    "            temp_status = single_result[\"status\"]\n",
    "            if b_a_seq == None:  # Critical transfers\n",
    "                single_result[\"status\"] = 6\n",
    "                Critical_count += 1\n",
    "            elif b_a_seq > 0:  # Missed transfers\n",
    "                single_result[\"status\"] = 1\n",
    "                Missed_count += 1\n",
    "            elif b_a_seq == 0:  # Normal transfers\n",
    "                single_result[\"status\"] = 0\n",
    "                Normal_count += 1\n",
    "            elif b_a_seq < 0:  # Preemptive transfers\n",
    "                single_result[\"status\"] = 2\n",
    "                Preemptive_count += 1\n",
    "            else:\n",
    "                print(single_result)\n",
    "                single_result[\"status\"] = 5\n",
    "                None_count += 1\n",
    "\n",
    "            # print(temp_status,\"=>\",single_result[\"status\"],flag )\n",
    "\n",
    "            Ded_count += 1\n",
    "        else:\n",
    "            if single_result[\"status\"] == 6:\n",
    "                Critical_count += 1\n",
    "            elif single_result[\"status\"] == 1:\n",
    "                Missed_count += 1\n",
    "            elif single_result[\"status\"] == 0:\n",
    "                Normal_count += 1\n",
    "            elif single_result[\"status\"] == 2:\n",
    "                Preemptive_count += 1\n",
    "            else:\n",
    "                None_count += 1\n",
    "    else:\n",
    "        None_count += 1\n",
    "\n",
    "    records_collections.append(single_result)\n",
    "    Total_count += 1\n",
    "    b = time.time()\n",
    "    # if Total_count % 1000 ==50:\n",
    "    if Total_count % 1000 == 50:\n",
    "        print(\"[\", single_date, \"]: \", Total_count, \"||\", Normal_count, \"|\", Missed_count, \"|\", Preemptive_count, \"|\", Critical_count, \"|\", None_count, \"||\",\n",
    "              round((Normal_count + Missed_count + Preemptive_count + Critical_count) / Total_count, 4), \"||\", round(Total_count / Max_count * 100, 4), \"%\", \"||\", Ded_count, \"||\", round(b - a_start, 2))\n",
    "\n",
    "    if Total_count % 10000 == 9999:\n",
    "        ass = time.time()\n",
    "        db_dedicated_collection.insert_many(records_collections)\n",
    "        records_collections = []\n",
    "        bss = time.time()\n",
    "        print(\"Insert\", Total_count / Max_count)\n",
    "\n",
    "db_dedicated_collection.insert_many(records_collections)\n",
    "print(\"Insert\", Total_count / Max_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = date(2018, 9, 3)\n",
    "end_date = date(2019, 1, 31)\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "pool = multiprocessing.Pool(processes=cores)\n",
    "date_range = daterange(start_date, end_date)\n",
    "output=[]\n",
    "output=pool.map(paralleling_transfers, date_range)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "#paralleling_transfers(start_date)\n",
    "\n",
    "#for each_date in daterange(start_date, end_date):\n",
    "#    paralleling_transfers(each_date)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
